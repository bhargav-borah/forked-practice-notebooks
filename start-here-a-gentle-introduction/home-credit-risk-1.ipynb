{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9120,"databundleVersionId":860599,"sourceType":"competition"}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports\n\nWe are using a typical data science stack: `numpy`, `pandas`, `sklearn`, `matplotlib`.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2024-09-28T05:23:46.765708Z","iopub.execute_input":"2024-09-28T05:23:46.766570Z","iopub.status.idle":"2024-09-28T05:23:48.159871Z","shell.execute_reply.started":"2024-09-28T05:23:46.766519Z","shell.execute_reply":"2024-09-28T05:23:48.158680Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Read the Data","metadata":{}},{"cell_type":"code","source":"# List files available\nprint(os.listdir('../input/'))","metadata":{"execution":{"iopub.status.busy":"2024-09-28T05:23:48.162193Z","iopub.execute_input":"2024-09-28T05:23:48.162849Z","iopub.status.idle":"2024-09-28T05:23:48.169007Z","shell.execute_reply.started":"2024-09-28T05:23:48.162787Z","shell.execute_reply":"2024-09-28T05:23:48.167884Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"['home-credit-default-risk']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Training data\ntrain_df = pd.read_csv('/kaggle/input/home-credit-default-risk/application_train.csv')\nprint('Training data shape: ', train_df.shape)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-28T05:23:48.170458Z","iopub.execute_input":"2024-09-28T05:23:48.171734Z","iopub.status.idle":"2024-09-28T05:23:55.489979Z","shell.execute_reply.started":"2024-09-28T05:23:48.171678Z","shell.execute_reply":"2024-09-28T05:23:55.488839Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Training data shape:  (307511, 122)\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n0      100002       1         Cash loans           M            N   \n1      100003       0         Cash loans           F            N   \n2      100004       0    Revolving loans           M            Y   \n3      100006       0         Cash loans           F            N   \n4      100007       0         Cash loans           M            N   \n\n  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n0               Y             0          202500.0    406597.5      24700.5   \n1               N             0          270000.0   1293502.5      35698.5   \n2               Y             0           67500.0    135000.0       6750.0   \n3               Y             0          135000.0    312682.5      29686.5   \n4               Y             0          121500.0    513000.0      21865.5   \n\n   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n0  ...                 0                0                0                0   \n1  ...                 0                0                0                0   \n2  ...                 0                0                0                0   \n3  ...                 0                0                0                0   \n4  ...                 0                0                0                0   \n\n  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n0                        0.0                       0.0   \n1                        0.0                       0.0   \n2                        0.0                       0.0   \n3                        NaN                       NaN   \n4                        0.0                       0.0   \n\n   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n0                         0.0                        0.0   \n1                         0.0                        0.0   \n2                         0.0                        0.0   \n3                         NaN                        NaN   \n4                         0.0                        0.0   \n\n   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n0                        0.0                         1.0  \n1                        0.0                         0.0  \n2                        0.0                         0.0  \n3                        NaN                         NaN  \n4                        0.0                         0.0  \n\n[5 rows x 122 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SK_ID_CURR</th>\n      <th>TARGET</th>\n      <th>NAME_CONTRACT_TYPE</th>\n      <th>CODE_GENDER</th>\n      <th>FLAG_OWN_CAR</th>\n      <th>FLAG_OWN_REALTY</th>\n      <th>CNT_CHILDREN</th>\n      <th>AMT_INCOME_TOTAL</th>\n      <th>AMT_CREDIT</th>\n      <th>AMT_ANNUITY</th>\n      <th>...</th>\n      <th>FLAG_DOCUMENT_18</th>\n      <th>FLAG_DOCUMENT_19</th>\n      <th>FLAG_DOCUMENT_20</th>\n      <th>FLAG_DOCUMENT_21</th>\n      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100002</td>\n      <td>1</td>\n      <td>Cash loans</td>\n      <td>M</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>202500.0</td>\n      <td>406597.5</td>\n      <td>24700.5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100003</td>\n      <td>0</td>\n      <td>Cash loans</td>\n      <td>F</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0</td>\n      <td>270000.0</td>\n      <td>1293502.5</td>\n      <td>35698.5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100004</td>\n      <td>0</td>\n      <td>Revolving loans</td>\n      <td>M</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>67500.0</td>\n      <td>135000.0</td>\n      <td>6750.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100006</td>\n      <td>0</td>\n      <td>Cash loans</td>\n      <td>F</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>135000.0</td>\n      <td>312682.5</td>\n      <td>29686.5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100007</td>\n      <td>0</td>\n      <td>Cash loans</td>\n      <td>M</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>121500.0</td>\n      <td>513000.0</td>\n      <td>21865.5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 122 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The training data has 307511 observations (each one a separate loan) and 122 columns including the `TARGET` (the label we want to predict).","metadata":{}},{"cell_type":"code","source":"# Testing data features\ntest_df = pd.read_csv('/kaggle/input/home-credit-default-risk/application_test.csv')\nprint('Testing data shape: ', test_df.shape)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-28T05:23:55.491604Z","iopub.execute_input":"2024-09-28T05:23:55.492061Z","iopub.status.idle":"2024-09-28T05:23:56.631136Z","shell.execute_reply.started":"2024-09-28T05:23:55.492003Z","shell.execute_reply":"2024-09-28T05:23:56.629973Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Testing data shape:  (48744, 121)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n0      100001         Cash loans           F            N               Y   \n1      100005         Cash loans           M            N               Y   \n2      100013         Cash loans           M            Y               Y   \n3      100028         Cash loans           F            N               Y   \n4      100038         Cash loans           M            Y               N   \n\n   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n0             0          135000.0    568800.0      20560.5         450000.0   \n1             0           99000.0    222768.0      17370.0         180000.0   \n2             0          202500.0    663264.0      69777.0         630000.0   \n3             2          315000.0   1575000.0      49018.5        1575000.0   \n4             1          180000.0    625500.0      32067.0         625500.0   \n\n   ... FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n0  ...                0                0                0                0   \n1  ...                0                0                0                0   \n2  ...                0                0                0                0   \n3  ...                0                0                0                0   \n4  ...                0                0                0                0   \n\n  AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_DAY  \\\n0                        0.0                        0.0   \n1                        0.0                        0.0   \n2                        0.0                        0.0   \n3                        0.0                        0.0   \n4                        NaN                        NaN   \n\n   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n0                         0.0                        0.0   \n1                         0.0                        0.0   \n2                         0.0                        0.0   \n3                         0.0                        0.0   \n4                         NaN                        NaN   \n\n   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n0                        0.0                         0.0  \n1                        0.0                         3.0  \n2                        1.0                         4.0  \n3                        0.0                         3.0  \n4                        NaN                         NaN  \n\n[5 rows x 121 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SK_ID_CURR</th>\n      <th>NAME_CONTRACT_TYPE</th>\n      <th>CODE_GENDER</th>\n      <th>FLAG_OWN_CAR</th>\n      <th>FLAG_OWN_REALTY</th>\n      <th>CNT_CHILDREN</th>\n      <th>AMT_INCOME_TOTAL</th>\n      <th>AMT_CREDIT</th>\n      <th>AMT_ANNUITY</th>\n      <th>AMT_GOODS_PRICE</th>\n      <th>...</th>\n      <th>FLAG_DOCUMENT_18</th>\n      <th>FLAG_DOCUMENT_19</th>\n      <th>FLAG_DOCUMENT_20</th>\n      <th>FLAG_DOCUMENT_21</th>\n      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100001</td>\n      <td>Cash loans</td>\n      <td>F</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>135000.0</td>\n      <td>568800.0</td>\n      <td>20560.5</td>\n      <td>450000.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100005</td>\n      <td>Cash loans</td>\n      <td>M</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>99000.0</td>\n      <td>222768.0</td>\n      <td>17370.0</td>\n      <td>180000.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100013</td>\n      <td>Cash loans</td>\n      <td>M</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>202500.0</td>\n      <td>663264.0</td>\n      <td>69777.0</td>\n      <td>630000.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100028</td>\n      <td>Cash loans</td>\n      <td>F</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>2</td>\n      <td>315000.0</td>\n      <td>1575000.0</td>\n      <td>49018.5</td>\n      <td>1575000.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100038</td>\n      <td>Cash loans</td>\n      <td>M</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>1</td>\n      <td>180000.0</td>\n      <td>625500.0</td>\n      <td>32067.0</td>\n      <td>625500.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 121 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The test set is considerably smaller and lacks a `TARGET` column.","metadata":{}},{"cell_type":"markdown","source":"## Exploratory Data Analysis\n\nExploratory Data Analysis (EDA) is an open-ended process where we calculate statistics and make figures to find trends, anomalies, patterns, or relationships within the data. The goal of EDA is to learn what our data can tell us. It generally starts out with a high level overview, then narrows in to specific areas of the data. The findings may be interesting in their own right, or they may be used to inform our modeling choices, such as by helping us decide which features to use.","metadata":{}},{"cell_type":"markdown","source":"### Examine the Distribution of the Target Column\n\nThe target is what we are asked to predict: either a 0 for the loan was repaid on time, or a 1 indicating the client had payment difficulties. We can first examine the number of loands falling into each category.","metadata":{}},{"cell_type":"code","source":"train_df['TARGET'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-09-28T05:23:56.633722Z","iopub.execute_input":"2024-09-28T05:23:56.634109Z","iopub.status.idle":"2024-09-28T05:23:56.653733Z","shell.execute_reply.started":"2024-09-28T05:23:56.634068Z","shell.execute_reply":"2024-09-28T05:23:56.652408Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"TARGET\n0    282686\n1     24825\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"train_df['TARGET'].value_counts(normalize=True) * 100","metadata":{"execution":{"iopub.status.busy":"2024-09-28T05:23:56.655273Z","iopub.execute_input":"2024-09-28T05:23:56.655768Z","iopub.status.idle":"2024-09-28T05:23:56.671393Z","shell.execute_reply.started":"2024-09-28T05:23:56.655714Z","shell.execute_reply":"2024-09-28T05:23:56.670184Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"TARGET\n0    91.927118\n1     8.072882\nName: proportion, dtype: float64"},"metadata":{}}]},{"cell_type":"markdown","source":"From this information, we see this is an [_imbalanced class problem_](http://www.chioka.in/class-imbalance-problem/). There are far more loans that were repaid on time than loans that were not repaid. Once we get into more sophisticated machine learning models, we can [weight the classes](http://xgboost.readthedocs.io/en/latest/parameter.html) by their representation in the data to reflect this imbalance. ","metadata":{}},{"cell_type":"markdown","source":"### Examine Missing Values\n\nNext we can look at the number and percentage of missing values in each column.","metadata":{}},{"cell_type":"code","source":"# Function to calculate missing values by column# Funct \ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","metadata":{"execution":{"iopub.status.busy":"2024-09-28T05:23:56.672825Z","iopub.execute_input":"2024-09-28T05:23:56.673222Z","iopub.status.idle":"2024-09-28T05:23:56.682716Z","shell.execute_reply.started":"2024-09-28T05:23:56.673184Z","shell.execute_reply":"2024-09-28T05:23:56.681595Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Missing values statistics\nmissing_values = missing_values_table(train_df)\nmissing_values.head(20).style.background_gradient(cmap='Reds')","metadata":{"execution":{"iopub.status.busy":"2024-09-28T05:23:56.684347Z","iopub.execute_input":"2024-09-28T05:23:56.684845Z","iopub.status.idle":"2024-09-28T05:23:57.832414Z","shell.execute_reply.started":"2024-09-28T05:23:56.684789Z","shell.execute_reply":"2024-09-28T05:23:57.831194Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Your selected dataframe has 122 columns.\nThere are 67 columns that have missing values.\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x7b0911d95f00>","text/html":"<style type=\"text/css\">\n#T_ae2c8_row0_col0, #T_ae2c8_row0_col1, #T_ae2c8_row1_col0, #T_ae2c8_row1_col1, #T_ae2c8_row2_col0, #T_ae2c8_row2_col1 {\n  background-color: #67000d;\n  color: #f1f1f1;\n}\n#T_ae2c8_row3_col0, #T_ae2c8_row4_col0, #T_ae2c8_row5_col0 {\n  background-color: #7a0510;\n  color: #f1f1f1;\n}\n#T_ae2c8_row3_col1, #T_ae2c8_row4_col1, #T_ae2c8_row5_col1 {\n  background-color: #7e0610;\n  color: #f1f1f1;\n}\n#T_ae2c8_row6_col0, #T_ae2c8_row6_col1, #T_ae2c8_row7_col1, #T_ae2c8_row8_col1, #T_ae2c8_row9_col1 {\n  background-color: #aa1016;\n  color: #f1f1f1;\n}\n#T_ae2c8_row7_col0, #T_ae2c8_row8_col0, #T_ae2c8_row9_col0 {\n  background-color: #ab1016;\n  color: #f1f1f1;\n}\n#T_ae2c8_row10_col0, #T_ae2c8_row11_col0, #T_ae2c8_row12_col0 {\n  background-color: #b91419;\n  color: #f1f1f1;\n}\n#T_ae2c8_row10_col1, #T_ae2c8_row11_col1, #T_ae2c8_row12_col1 {\n  background-color: #bc141a;\n  color: #f1f1f1;\n}\n#T_ae2c8_row13_col0, #T_ae2c8_row13_col1, #T_ae2c8_row14_col0, #T_ae2c8_row14_col1, #T_ae2c8_row15_col0, #T_ae2c8_row15_col1 {\n  background-color: #e02c26;\n  color: #f1f1f1;\n}\n#T_ae2c8_row16_col0 {\n  background-color: #ed392b;\n  color: #f1f1f1;\n}\n#T_ae2c8_row16_col1 {\n  background-color: #ee3a2c;\n  color: #f1f1f1;\n}\n#T_ae2c8_row17_col0, #T_ae2c8_row17_col1, #T_ae2c8_row18_col0, #T_ae2c8_row18_col1, #T_ae2c8_row19_col0, #T_ae2c8_row19_col1 {\n  background-color: #fff5f0;\n  color: #000000;\n}\n</style>\n<table id=\"T_ae2c8\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_ae2c8_level0_col0\" class=\"col_heading level0 col0\" >Missing Values</th>\n      <th id=\"T_ae2c8_level0_col1\" class=\"col_heading level0 col1\" >% of Total Values</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_ae2c8_level0_row0\" class=\"row_heading level0 row0\" >COMMONAREA_MEDI</th>\n      <td id=\"T_ae2c8_row0_col0\" class=\"data row0 col0\" >214865</td>\n      <td id=\"T_ae2c8_row0_col1\" class=\"data row0 col1\" >69.900000</td>\n    </tr>\n    <tr>\n      <th id=\"T_ae2c8_level0_row1\" class=\"row_heading level0 row1\" >COMMONAREA_AVG</th>\n      <td id=\"T_ae2c8_row1_col0\" class=\"data row1 col0\" >214865</td>\n      <td id=\"T_ae2c8_row1_col1\" class=\"data row1 col1\" >69.900000</td>\n    </tr>\n    <tr>\n      <th id=\"T_ae2c8_level0_row2\" class=\"row_heading level0 row2\" >COMMONAREA_MODE</th>\n      <td id=\"T_ae2c8_row2_col0\" class=\"data row2 col0\" >214865</td>\n      <td id=\"T_ae2c8_row2_col1\" class=\"data row2 col1\" >69.900000</td>\n    </tr>\n    <tr>\n      <th id=\"T_ae2c8_level0_row3\" class=\"row_heading level0 row3\" >NONLIVINGAPARTMENTS_MEDI</th>\n      <td id=\"T_ae2c8_row3_col0\" class=\"data row3 col0\" >213514</td>\n      <td id=\"T_ae2c8_row3_col1\" class=\"data row3 col1\" >69.400000</td>\n    </tr>\n    <tr>\n      <th id=\"T_ae2c8_level0_row4\" class=\"row_heading level0 row4\" >NONLIVINGAPARTMENTS_MODE</th>\n      <td id=\"T_ae2c8_row4_col0\" class=\"data row4 col0\" >213514</td>\n      <td id=\"T_ae2c8_row4_col1\" class=\"data row4 col1\" >69.400000</td>\n    </tr>\n    <tr>\n      <th id=\"T_ae2c8_level0_row5\" class=\"row_heading level0 row5\" >NONLIVINGAPARTMENTS_AVG</th>\n      <td id=\"T_ae2c8_row5_col0\" class=\"data row5 col0\" >213514</td>\n      <td id=\"T_ae2c8_row5_col1\" class=\"data row5 col1\" >69.400000</td>\n    </tr>\n    <tr>\n      <th id=\"T_ae2c8_level0_row6\" class=\"row_heading level0 row6\" >FONDKAPREMONT_MODE</th>\n      <td id=\"T_ae2c8_row6_col0\" class=\"data row6 col0\" >210295</td>\n      <td id=\"T_ae2c8_row6_col1\" class=\"data row6 col1\" >68.400000</td>\n    </tr>\n    <tr>\n      <th id=\"T_ae2c8_level0_row7\" class=\"row_heading level0 row7\" >LIVINGAPARTMENTS_MODE</th>\n      <td id=\"T_ae2c8_row7_col0\" class=\"data row7 col0\" >210199</td>\n      <td id=\"T_ae2c8_row7_col1\" class=\"data row7 col1\" >68.400000</td>\n    </tr>\n    <tr>\n      <th id=\"T_ae2c8_level0_row8\" class=\"row_heading level0 row8\" >LIVINGAPARTMENTS_MEDI</th>\n      <td id=\"T_ae2c8_row8_col0\" class=\"data row8 col0\" >210199</td>\n      <td id=\"T_ae2c8_row8_col1\" class=\"data row8 col1\" >68.400000</td>\n    </tr>\n    <tr>\n      <th id=\"T_ae2c8_level0_row9\" class=\"row_heading level0 row9\" >LIVINGAPARTMENTS_AVG</th>\n      <td id=\"T_ae2c8_row9_col0\" class=\"data row9 col0\" >210199</td>\n      <td id=\"T_ae2c8_row9_col1\" class=\"data row9 col1\" >68.400000</td>\n    </tr>\n    <tr>\n      <th id=\"T_ae2c8_level0_row10\" class=\"row_heading level0 row10\" >FLOORSMIN_MODE</th>\n      <td id=\"T_ae2c8_row10_col0\" class=\"data row10 col0\" >208642</td>\n      <td id=\"T_ae2c8_row10_col1\" class=\"data row10 col1\" >67.800000</td>\n    </tr>\n    <tr>\n      <th id=\"T_ae2c8_level0_row11\" class=\"row_heading level0 row11\" >FLOORSMIN_MEDI</th>\n      <td id=\"T_ae2c8_row11_col0\" class=\"data row11 col0\" >208642</td>\n      <td id=\"T_ae2c8_row11_col1\" class=\"data row11 col1\" >67.800000</td>\n    </tr>\n    <tr>\n      <th id=\"T_ae2c8_level0_row12\" class=\"row_heading level0 row12\" >FLOORSMIN_AVG</th>\n      <td id=\"T_ae2c8_row12_col0\" class=\"data row12 col0\" >208642</td>\n      <td id=\"T_ae2c8_row12_col1\" class=\"data row12 col1\" >67.800000</td>\n    </tr>\n    <tr>\n      <th id=\"T_ae2c8_level0_row13\" class=\"row_heading level0 row13\" >YEARS_BUILD_MODE</th>\n      <td id=\"T_ae2c8_row13_col0\" class=\"data row13 col0\" >204488</td>\n      <td id=\"T_ae2c8_row13_col1\" class=\"data row13 col1\" >66.500000</td>\n    </tr>\n    <tr>\n      <th id=\"T_ae2c8_level0_row14\" class=\"row_heading level0 row14\" >YEARS_BUILD_MEDI</th>\n      <td id=\"T_ae2c8_row14_col0\" class=\"data row14 col0\" >204488</td>\n      <td id=\"T_ae2c8_row14_col1\" class=\"data row14 col1\" >66.500000</td>\n    </tr>\n    <tr>\n      <th id=\"T_ae2c8_level0_row15\" class=\"row_heading level0 row15\" >YEARS_BUILD_AVG</th>\n      <td id=\"T_ae2c8_row15_col0\" class=\"data row15 col0\" >204488</td>\n      <td id=\"T_ae2c8_row15_col1\" class=\"data row15 col1\" >66.500000</td>\n    </tr>\n    <tr>\n      <th id=\"T_ae2c8_level0_row16\" class=\"row_heading level0 row16\" >OWN_CAR_AGE</th>\n      <td id=\"T_ae2c8_row16_col0\" class=\"data row16 col0\" >202929</td>\n      <td id=\"T_ae2c8_row16_col1\" class=\"data row16 col1\" >66.000000</td>\n    </tr>\n    <tr>\n      <th id=\"T_ae2c8_level0_row17\" class=\"row_heading level0 row17\" >LANDAREA_AVG</th>\n      <td id=\"T_ae2c8_row17_col0\" class=\"data row17 col0\" >182590</td>\n      <td id=\"T_ae2c8_row17_col1\" class=\"data row17 col1\" >59.400000</td>\n    </tr>\n    <tr>\n      <th id=\"T_ae2c8_level0_row18\" class=\"row_heading level0 row18\" >LANDAREA_MEDI</th>\n      <td id=\"T_ae2c8_row18_col0\" class=\"data row18 col0\" >182590</td>\n      <td id=\"T_ae2c8_row18_col1\" class=\"data row18 col1\" >59.400000</td>\n    </tr>\n    <tr>\n      <th id=\"T_ae2c8_level0_row19\" class=\"row_heading level0 row19\" >LANDAREA_MODE</th>\n      <td id=\"T_ae2c8_row19_col0\" class=\"data row19 col0\" >182590</td>\n      <td id=\"T_ae2c8_row19_col1\" class=\"data row19 col1\" >59.400000</td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"When it comes time to build our machine learning models, we will have to fill in these missing values (known as imputation). In later work, we will use models such as XGBoost that can [handle missing values with no need for imputation](https://stats.stackexchange.com/questions/235489/xgboost-can-handle-missing-data-in-the-forecasting-phase). Another option would be to drop columns with a high percentage of missing values, although it is impossible to know ahead of time if these columns will be helpful to our model. Therefore, we will keep all of the columns for now.","metadata":{}},{"cell_type":"markdown","source":"## Column Types\n\nLet's look at the number of columns of each data type. `int64` and `float64` are numeric variables ([which can be either discrete or continuous](https://stats.stackexchange.com/questions/206/what-is-the-difference-between-discrete-data-and-continuous-data)). `object` columns contain strings and are  [categorical features.](http://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/supporting-topics/basics/what-are-categorical-discrete-and-continuous-variables/) . ","metadata":{}},{"cell_type":"code","source":"# Number of each type of column\ntrain_df.dtypes.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-09-28T05:24:04.904994Z","iopub.execute_input":"2024-09-28T05:24:04.905479Z","iopub.status.idle":"2024-09-28T05:24:04.915630Z","shell.execute_reply.started":"2024-09-28T05:24:04.905404Z","shell.execute_reply":"2024-09-28T05:24:04.914298Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"float64    65\nint64      41\nobject     16\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"Now let's look at the number of unique entries in each of the `object` (categorical) columns.","metadata":{}},{"cell_type":"code","source":"# Number of unique classes in each object column\ntrain_df.select_dtypes(include=['object']).apply(pd.Series.nunique, axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T05:25:27.445451Z","iopub.execute_input":"2024-09-28T05:25:27.446009Z","iopub.status.idle":"2024-09-28T05:25:27.941801Z","shell.execute_reply.started":"2024-09-28T05:25:27.445955Z","shell.execute_reply":"2024-09-28T05:25:27.940495Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"NAME_CONTRACT_TYPE             2\nCODE_GENDER                    3\nFLAG_OWN_CAR                   2\nFLAG_OWN_REALTY                2\nNAME_TYPE_SUITE                7\nNAME_INCOME_TYPE               8\nNAME_EDUCATION_TYPE            5\nNAME_FAMILY_STATUS             6\nNAME_HOUSING_TYPE              6\nOCCUPATION_TYPE               18\nWEEKDAY_APPR_PROCESS_START     7\nORGANIZATION_TYPE             58\nFONDKAPREMONT_MODE             4\nHOUSETYPE_MODE                 3\nWALLSMATERIAL_MODE             7\nEMERGENCYSTATE_MODE            2\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"Most of the categorical variables have a relatively small number of unique entries. We will need to find a way to deal with these categorical variables!","metadata":{}},{"cell_type":"markdown","source":"## Encoding Categorical Variables\n\nBefore we go any further, we need to deal with pesky categorical variables. A machine learning model unfortunately cannot deal with categorical variables (except for some models such as [LightGBM](https://lightgbm.readthedocs.io/en/latest/Features.html)). Therefore, we have to find a way to encode these variables as numbers before handing them off to the model. There are two main ways to carry out this process:\n\n* Label Encoding: Assign each unique category in a categorical variable with an integer. No new columns are created. An example is shown below:\n![image](https://raw.githubusercontent.com/WillKoehrsen/Machine-Learning-Projects/master/label_encoding.png)\n\n* One-hot encoding: Create a new column for each unique category in a categorical variable. Each observation receives a 1 in the column for its corresponding category and a 0 in all other new columns.\n![image](https://raw.githubusercontent.com/WillKoehrsen/Machine-Learning-Projects/master/one_hot_encoding.png)\n\nThe problem with label encoding is that it gives the categories an arbitrary ordering. The value assigned to each of the categories is random and does not reflect any inherent aspect of the category. In the example above, programmer receives a 4 and data scientist a 1, but if we did the same process again, the labels could be reversed or completely different. The actual assignment of the integers is arbitrary. Therefore, when we perform label encoding, the model might use the relative value of the feature (for example programmer = 4 and data scientist = 1) to assign weights which is not what we want, If we only have two unique values for a categorical variable (such as Male/Female), the label encoding is fine, but for more than 2 unique categories, one-hot encoding is a safe option.\n\nThere is some debate about the relative merits of these approaches, and some models can deal with label encoded categorical variables with no issues. [Here is a good StackOverflow discussion](https://datascience.stackexchange.com/questions/9443/when-to-use-one-hot-encoding-vs-labelencoder-vs-dictvectorizor). I think (and this is just a personal opinion) for categorical variables with many classe, one-hot encoding is the safest option because it does not impose arbitrary values to categories. The only downside to one-hot encoding is that the number of features (dimensions of the data) can explode with categorical variables with many categoires. To deal with this, we can perform one-hot-encoding followed by [PCA](http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf) or other [dimensionality reduction methods](https://www.analyticsvidhya.com/blog/2015/07/dimension-reduction-methods/) to reduce the number of dimensions (while still trying to preserve the information).\n\nIn this notebook, we will use Label Encoding for categorical variables with only 2 categories and one-hot encoding for any categorical variables with more than 2 categories. This process may need to change as we get further into the project, but for now, we will see where this gets us. (We will also not use any dimensionality reduction in this notebook but we will explore that in future iterations).","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}